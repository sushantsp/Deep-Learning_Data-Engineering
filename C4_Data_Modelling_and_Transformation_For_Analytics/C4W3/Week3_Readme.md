## Learning Objectives
* Identify batch transformation use cases and patterns
* Compare an in-memory processing framework like Spark, and a processing framework that involves disk read and write operations, such as Hadoop
* Describe the technical considerations for choosing a distributed processing framework, such as Spark, vs a non-distributed framework like Pandas dataframes
* Describe the technical considerations for using SparkSQL vs DataFrames when transforming data using PySpark
* Explain how streaming transformation works with a near-real time processing engine such as Spark Structured Streaming


### Week Overview

![alt text](.images/Overview_1.png)
![alt text](.images/Overview_2.png)


**Distributed Processing Frameworks:**

_Hadoop MapReduce:_ Understand its use of disks for data storage and processing. Although considered a legacy technology, it's important to grasp the MapReduce paradigm as it influences modern distributed systems.

_Spark:_ Learn about this in-memory processing framework, which is often preferred for its performance and scalability.